{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Limpeza e Filtragem\n",
    "O Problema: Temos gigabytes de dados misturados (Renda Fixa, Cambial, Multimercado). O desafio pede especificamente a \"classe de AÃ§Ãµes\".\n",
    "\n",
    "Script:\n",
    "\n",
    "1 - Ler o arquivo de Cadastro (cad_fi.csv) para pegar os CNPJs que sÃ£o de \"AÃ§Ãµes\".\n",
    "2 - Ler os arquivos mensais (inf_diario...) um por um.\n",
    "3 - Filtrar apenas as linhas que tÃªm esses CNPJs.\n",
    "4 - Salvar tudo num arquivo Ãºnico e otimizado (formato Parquet, que Ã© muito mais rÃ¡pido que CSV para leitura posterior)."
   ],
   "id": "7a547bfdfd264243"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importamos as bibliotecas e definimos os caminhos. Usaremos o cad_fi.csv para filtrar os fundos de interesse antes de processar as sÃ©ries temporais pesadas.",
   "id": "3cebf741fc8b773c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Imports e ConfiguraÃ§Ã£o\n",
    "Importamos as bibliotecas e definimos os caminhos. Usaremos o cad_fi.csv para filtrar os fundos de interesse antes de processar as sÃ©ries temporais pesadas."
   ],
   "id": "1d5717752085d2ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T00:28:45.009479100Z",
     "start_time": "2025-12-20T00:28:44.991206700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import gc # Garbage Collector para limpar memÃ³ria RAM\n",
    "\n",
    "# Caminhos\n",
    "RAW_DIR = '../data/raw'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)"
   ],
   "id": "c9008164f4aed950",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Filtrando os CNPJs de AÃ§Ãµes\n",
    "\n",
    "Segundo o escopo do desafio, devemos utilizar a classe de AÃ§Ãµes. Carregamos o cadastro (cad_fi.csv), filtramos por CLASSE == 'Fundo de AÃ§Ãµes' e status EM FUNCIONAMENTO NORMAL. Isso gera uma lista de CNPJs vÃ¡lidos (\"White List\") para aplicarmos nos dados diÃ¡rios."
   ],
   "id": "f5bb235c115ff8d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T00:28:45.327313200Z",
     "start_time": "2025-12-20T00:28:45.011484800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"ðŸ“‚ Carregando cadastro de fundos...\")\n",
    "\n",
    "# LÃª o cadastro (encoding 'latin1' Ã© padrÃ£o de arquivos governamentais antigos no BR)\n",
    "df_cad = pd.read_csv(f'{RAW_DIR}/cad_fi.csv', sep=';', encoding='latin1', low_memory=False)\n",
    "\n",
    "# Normaliza colunas para evitar erros de maiÃºsculas/minÃºsculas\n",
    "df_cad.columns = df_cad.columns.str.upper()\n",
    "\n",
    "# FILTRO 1: Apenas classe 'AÃ§Ãµes'\n",
    "# Obs: Na CVM, a classe exata geralmente vem como 'Fundo de AÃ§Ãµes'\n",
    "filtro_acoes = df_cad['CLASSE'] == 'Fundo de AÃ§Ãµes'\n",
    "\n",
    "# FILTRO 2: Apenas fundos em funcionamento (opcional, mas remove lixo)\n",
    "filtro_ativo = df_cad['SIT'] == 'EM FUNCIONAMENTO NORMAL'\n",
    "\n",
    "# Aplica filtros\n",
    "df_acoes = df_cad[filtro_acoes & filtro_ativo].copy()\n",
    "\n",
    "# Cria a lista de CNPJs permitidos (nossa \"White List\")\n",
    "cnpjs_acoes = set(df_acoes['CNPJ_FUNDO'].unique())\n",
    "\n",
    "print(f\"âœ… Total de fundos de AÃ§Ãµes encontrados: {len(cnpjs_acoes)}\")\n",
    "print(f\"Exemplos de Classes no arquivo: {df_cad['CLASSE'].unique()[:5]}\")"
   ],
   "id": "4876f79ac4c42767",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Carregando cadastro de fundos...\n",
      "âœ… Total de fundos de AÃ§Ãµes encontrados: 0\n",
      "Exemplos de Classes no arquivo: [nan 'Multimercado' 'AÃ§Ãµes' 'Renda Fixa' 'Referenciado']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Loop de Processamento (O \"Triturador\")\n",
    "\n",
    "Agora iteramos sobre todos os arquivos mensais baixados. Para cada arquivo:\n",
    "\n",
    "1 - Carregamos o CSV na memÃ³ria.\n",
    "2 - Filtramos mantendo apenas os CNPJs de AÃ§Ãµes identificados no passo anterior.\n",
    "3 - Acumulamos o resultado.\n",
    "\n",
    "OtimizaÃ§Ã£o: Usamos gc.collect() para liberar memÃ³ria RAM entre as iteraÃ§Ãµes, evitando que o computador trave com o volume de dados."
   ],
   "id": "293f6e67707a912c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T00:28:57.735963600Z",
     "start_time": "2025-12-20T00:28:45.329312400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "arquivos_diarios = sorted(glob.glob(f'{RAW_DIR}/inf_diario_fi_*.csv'))\n",
    "dfs_filtrados = []\n",
    "\n",
    "print(f\"ðŸš€ Iniciando processamento de {len(arquivos_diarios)} arquivos mensais...\")\n",
    "\n",
    "colunas_importantes = ['CNPJ_FUNDO', 'DT_COMPTC', 'VL_QUOTA', 'VL_PATRIM_LIQ', 'CAPTC_DIA', 'RESG_DIA', 'NR_COTST']\n",
    "\n",
    "for arquivo in arquivos_diarios:\n",
    "    try:\n",
    "        # LÃª o arquivo\n",
    "        df_mes = pd.read_csv(arquivo, sep=';', encoding='latin1', low_memory=False)\n",
    "\n",
    "        # 1. Normaliza colunas (MaiÃºsculas e sem espaÃ§os)\n",
    "        df_mes.columns = df_mes.columns.str.upper().str.strip()\n",
    "\n",
    "        # 2. ADAPTAÃ‡ÃƒO RESOLUÃ‡ÃƒO 175: Renomeia CNPJ_FUNDO_CLASSE para CNPJ_FUNDO\n",
    "        if 'CNPJ_FUNDO_CLASSE' in df_mes.columns and 'CNPJ_FUNDO' not in df_mes.columns:\n",
    "            df_mes.rename(columns={'CNPJ_FUNDO_CLASSE': 'CNPJ_FUNDO'}, inplace=True)\n",
    "\n",
    "        # 3. Verifica se a coluna CNPJ agora existe\n",
    "        if 'CNPJ_FUNDO' in df_mes.columns:\n",
    "            # Filtra pelos CNPJs de AÃ§Ãµes (nossa \"White List\")\n",
    "            df_mes = df_mes[df_mes['CNPJ_FUNDO'].isin(cnpjs_acoes)]\n",
    "\n",
    "            if not df_mes.empty:\n",
    "                # Seleciona apenas colunas essenciais para economizar memÃ³ria e evitar erros de colunas extras\n",
    "                cols_to_keep = [c for c in colunas_importantes if c in df_mes.columns]\n",
    "                df_mes = df_mes[cols_to_keep]\n",
    "\n",
    "                dfs_filtrados.append(df_mes)\n",
    "        else:\n",
    "            # Mostra as primeiras 5 colunas para entendermos o que veio\n",
    "            print(f\"âš ï¸ Pulei {os.path.basename(arquivo)}: Coluna CNPJ nÃ£o encontrada. Headers: {list(df_mes.columns)[:5]}\")\n",
    "\n",
    "        # Limpeza de memÃ³ria\n",
    "        del df_mes\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro ao ler {os.path.basename(arquivo)}: {e}\")\n",
    "\n",
    "# ConcatenaÃ§Ã£o Final\n",
    "if len(dfs_filtrados) > 0:\n",
    "    print(\"ðŸ”„ Concatenando todos os meses...\")\n",
    "    df_final = pd.concat(dfs_filtrados, ignore_index=True)\n",
    "\n",
    "    # Tratamento final de tipos\n",
    "    df_final['DT_COMPTC'] = pd.to_datetime(df_final['DT_COMPTC'])\n",
    "    df_final.sort_values(by=['CNPJ_FUNDO', 'DT_COMPTC'], inplace=True)\n",
    "\n",
    "    # Salvar\n",
    "    arquivo_saida = f'{PROCESSED_DIR}/base_acoes_consolidada.parquet'\n",
    "    df_final.to_parquet(arquivo_saida, index=False)\n",
    "    print(f\"âœ… SUCESSO! Base salva: {df_final.shape[0]} linhas. Arquivo: {arquivo_saida}\")\n",
    "else:\n",
    "    print(\"ðŸ’€ ERRO: Nenhum dado restou apÃ³s os filtros.\")"
   ],
   "id": "1d17197d0ae80dfb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Iniciando processamento de 25 arquivos mensais...\n",
      "ðŸ’€ ERRO: Nenhum dado restou apÃ³s os filtros.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Salvando em Parquet\n",
    "\n",
    "\n",
    "Salvamos o resultado consolidado em formato Parquet.\n",
    "Por que Parquet? Ocupa ~80% menos espaÃ§o em disco que CSV.\n",
    "MantÃ©m os tipos de dados (datas, nÃºmeros) corretos, evitando ter que converter tudo de novo na prÃ³xima etapa."
   ],
   "id": "fccad998c391886f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T00:28:57.777357300Z",
     "start_time": "2025-12-20T00:28:57.751557200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Converte a coluna de data para datetime (essencial para sÃ©ries temporais)\n",
    "df_final['DT_COMPTC'] = pd.to_datetime(df_final['DT_COMPTC'])\n",
    "\n",
    "# Ordena por Fundo e Data\n",
    "df_final.sort_values(by=['CNPJ_FUNDO', 'DT_COMPTC'], inplace=True)\n",
    "\n",
    "arquivo_saida = f'{PROCESSED_DIR}/base_acoes_consolidada.parquet'\n",
    "print(f\"ðŸ’¾ Salvando em: {arquivo_saida}\")\n",
    "\n",
    "# Salva em Parquet (requer biblioteca pyarrow ou fastparquet instalada)\n",
    "df_final.to_parquet(arquivo_saida, index=False)\n",
    "\n",
    "print(\"âœ… Processo de Limpeza ConcluÃ­do!\")"
   ],
   "id": "203aea49afd45340",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Converte a coluna de data para datetime (essencial para sÃ©ries temporais)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m df_final[\u001B[33m'\u001B[39m\u001B[33mDT_COMPTC\u001B[39m\u001B[33m'\u001B[39m] = pd.to_datetime(\u001B[43mdf_final\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mDT_COMPTC\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Ordena por Fundo e Data\u001B[39;00m\n\u001B[32m      5\u001B[39m df_final.sort_values(by=[\u001B[33m'\u001B[39m\u001B[33mCNPJ_FUNDO\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mDT_COMPTC\u001B[39m\u001B[33m'\u001B[39m], inplace=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mNameError\u001B[39m: name 'df_final' is not defined"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
