{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Limpeza e Filtragem\n",
    "O Problema: Temos gigabytes de dados misturados (Renda Fixa, Cambial, Multimercado). O desafio pede especificamente a \"classe de AÃ§Ãµes\".\n",
    "\n",
    "Script:\n",
    "\n",
    "1 - Ler o arquivo de Cadastro (cad_fi.csv) para pegar os CNPJs que sÃ£o de \"AÃ§Ãµes\".\n",
    "2 - Ler os arquivos mensais (inf_diario...) um por um.\n",
    "3 - Filtrar apenas as linhas que tÃªm esses CNPJs.\n",
    "4 - Salvar tudo num arquivo Ãºnico e otimizado (formato Parquet, que Ã© muito mais rÃ¡pido que CSV para leitura posterior)."
   ],
   "id": "7a547bfdfd264243"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importamos as bibliotecas e definimos os caminhos. Usaremos o cad_fi.csv para filtrar os fundos de interesse antes de processar as sÃ©ries temporais pesadas.",
   "id": "3cebf741fc8b773c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Imports e ConfiguraÃ§Ã£o\n",
    "Importamos as bibliotecas e definimos os caminhos. Usaremos o cad_fi.csv para filtrar os fundos de interesse antes de processar as sÃ©ries temporais pesadas."
   ],
   "id": "1d5717752085d2ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Filtrando os CNPJs de AÃ§Ãµes\n",
    "\n",
    "Segundo o escopo do desafio, devemos utilizar a classe de AÃ§Ãµes. Carregamos o cadastro (cad_fi.csv), filtramos por CLASSE == 'Fundo de AÃ§Ãµes' e status EM FUNCIONAMENTO NORMAL. Isso gera uma lista de CNPJs vÃ¡lidos (\"White List\") para aplicarmos nos dados diÃ¡rios."
   ],
   "id": "f5bb235c115ff8d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Loop de Processamento (O \"Triturador\")\n",
    "\n",
    "Agora iteramos sobre todos os arquivos mensais baixados. Para cada arquivo:\n",
    "\n",
    "1 - Carregamos o CSV na memÃ³ria.\n",
    "2 - Filtramos mantendo apenas os CNPJs de AÃ§Ãµes identificados no passo anterior.\n",
    "3 - Acumulamos o resultado.\n",
    "\n",
    "OtimizaÃ§Ã£o: Usamos gc.collect() para liberar memÃ³ria RAM entre as iteraÃ§Ãµes, evitando que o computador trave com o volume de dados."
   ],
   "id": "293f6e67707a912c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Salvando em Parquet (CORRIGIR)\n",
    "\n",
    "\n",
    "Salvamos o resultado consolidado em formato Parquet. (corrigir)\n",
    "Por que Parquet? Ocupa ~80% menos espaÃ§o em disco que CSV.\n",
    "MantÃ©m os tipos de dados (datas, nÃºmeros) corretos, evitando ter que converter tudo de novo na prÃ³xima etapa."
   ],
   "id": "fccad998c391886f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T00:48:29.512069100Z",
     "start_time": "2025-12-20T00:48:16.285757400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CONFIGURAÃ‡ÃƒO\n",
    "# ==============================================================================\n",
    "RAW_DIR = '../data/raw'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Lista dos arquivos\n",
    "arquivos_diarios = sorted(glob.glob(f'{RAW_DIR}/inf_diario_fi_*.csv'))\n",
    "colunas_importantes = ['CNPJ_FUNDO', 'DT_COMPTC', 'VL_QUOTA', 'VL_PATRIM_LIQ', 'CAPTC_DIA', 'RESG_DIA', 'NR_COTST']\n",
    "\n",
    "print(f\"ðŸš€ Iniciando Processamento (Modo CSV)...\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. FILTRO DE AÃ‡Ã•ES (WHITE LIST)\n",
    "# ==============================================================================\n",
    "print(\"ðŸ“‚ Lendo Cadastro...\")\n",
    "try:\n",
    "    df_cad = pd.read_csv(f'{RAW_DIR}/cad_fi.csv', sep=';', encoding='latin1', low_memory=False)\n",
    "    df_cad.columns = df_cad.columns.str.upper().str.strip()\n",
    "\n",
    "    # Filtro Corrigido\n",
    "    filtro_acoes = df_cad['CLASSE'].str.strip() == 'AÃ§Ãµes'\n",
    "    filtro_ativo = df_cad['SIT'] == 'EM FUNCIONAMENTO NORMAL'\n",
    "    cnpjs_acoes = set(df_cad[filtro_acoes & filtro_ativo]['CNPJ_FUNDO'].unique())\n",
    "\n",
    "    del df_cad\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(f\"Erro no cadastro: {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. LEITURA DOS ARQUIVOS\n",
    "# ==============================================================================\n",
    "dfs_filtrados = []\n",
    "print(f\"ðŸ”„ Lendo {len(arquivos_diarios)} arquivos...\")\n",
    "\n",
    "for arquivo in arquivos_diarios:\n",
    "    try:\n",
    "        df_mes = pd.read_csv(arquivo, sep=';', encoding='latin1', low_memory=False)\n",
    "        df_mes.columns = df_mes.columns.str.upper().str.strip()\n",
    "\n",
    "        # CorreÃ§Ã£o ResoluÃ§Ã£o 175\n",
    "        if 'CNPJ_FUNDO_CLASSE' in df_mes.columns and 'CNPJ_FUNDO' not in df_mes.columns:\n",
    "            df_mes.rename(columns={'CNPJ_FUNDO_CLASSE': 'CNPJ_FUNDO'}, inplace=True)\n",
    "\n",
    "        if 'CNPJ_FUNDO' in df_mes.columns:\n",
    "            df_mes = df_mes[df_mes['CNPJ_FUNDO'].isin(cnpjs_acoes)]\n",
    "            if not df_mes.empty:\n",
    "                cols = [c for c in colunas_importantes if c in df_mes.columns]\n",
    "                dfs_filtrados.append(df_mes[cols])\n",
    "\n",
    "        del df_mes\n",
    "        gc.collect()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. SALVAMENTO EM CSV (A SOLUÃ‡ÃƒO DEFINITIVA)\n",
    "# ==============================================================================\n",
    "if len(dfs_filtrados) > 0:\n",
    "    print(\"ðŸ§© Concatenando...\")\n",
    "    df_final = pd.concat(dfs_filtrados, ignore_index=True)\n",
    "\n",
    "    print(\"ðŸ“… Ajustando Datas...\")\n",
    "    df_final['DT_COMPTC'] = pd.to_datetime(df_final['DT_COMPTC'])\n",
    "    df_final.sort_values(by=['CNPJ_FUNDO', 'DT_COMPTC'], inplace=True)\n",
    "\n",
    "    # --- MUDANÃ‡A AQUI: CSV EM VEZ DE PARQUET ---\n",
    "    arquivo_saida = f'{PROCESSED_DIR}/base_acoes_consolidada.csv'\n",
    "\n",
    "    print(f\"ðŸ’¾ Salvando em CSV: {arquivo_saida}\")\n",
    "    df_final.to_csv(arquivo_saida, index=False, sep=';')\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"âœ… SUCESSO! Arquivo CSV salvo.\")\n",
    "    print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"ðŸ’€ Erro: Lista vazia.\")"
   ],
   "id": "70dfc6e2df63f7d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Iniciando Processamento (Modo CSV)...\n",
      "ðŸ“‚ Lendo Cadastro...\n",
      "ðŸ”„ Lendo 25 arquivos...\n",
      "ðŸ§© Concatenando...\n",
      "ðŸ“… Ajustando Datas...\n",
      "ðŸ’¾ Salvando em CSV: ../data/processed/base_acoes_consolidada.csv\n",
      "------------------------------\n",
      "âœ… SUCESSO! Arquivo CSV salvo.\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
